import argparse
import logging
from pathlib import Path
from typing import List, Dict

import numpy as np
import pandas as pd
import torch
from torch import nn
from torch.utils.data import DataLoader
from tqdm import tqdm

from config import Config
from data import load_train_val_examples, load_test_examples, \
    GAPExample, GAPLabel, GAPDataset
from model import Model


logger = logging.getLogger(__name__)


def generate_predictions(
        model: nn.Module, config: Config,
        examples: List[GAPExample]) -> pd.DataFrame:
    df_parts = []
    for flip_prob in [0, 1]:
        data_loader = DataLoader(
            GAPDataset(examples, flip_prob=flip_prob),
            batch_size=config.batch_size, collate_fn=lambda x: x)
        with torch.no_grad():
            ids, predictions = [], []
            for batch in tqdm(data_loader, unit='batch', ncols=80, leave=False):
                ids.extend(e.id for e in batch)
                logits = model.forward(batch)
                probs = torch.nn.functional.softmax(logits, dim=1)
                predictions.append(probs.cpu().detach().numpy())
        df = pd.DataFrame(np.concatenate(predictions))
        df.columns = [l.name for l in GAPLabel]
        df.insert(0, 'ID', ids)
        if flip_prob == 1:
            flip_columns = list(df.columns)
            flip_columns[1] = df.columns[2]
            flip_columns[2] = df.columns[1]
            df.columns = flip_columns
        df_parts.append(df.set_index('ID'))

    # Sum the two predictions an normalize the scores
    df = (df_parts[0] + df_parts[1])
    df = df.div(df.sum(axis=1), axis=0)

    # Add the labels if they are available
    if examples[0].label is not None:
        df['LABEL'] = [e.label.name for e in examples]

    df.reset_index(inplace=True)
    return df


def optimize_thresholds(predictions: pd.DataFrame, threshold_steps: int) -> Dict[str, float]:
    loss = calculate_losses(predictions)['LOSS'].mean()
    logger.info('Loss without any threshold applied: %g', loss)

    thresholds: Dict[str, float] = {}
    for label in [l.name for l in GAPLabel]:
        best_loss, best_threshold = np.inf, np.nan
        for threshold in np.linspace(1/3, 1, threshold_steps):
            df = apply_thresholds(predictions.copy(), {label: threshold})
            loss = calculate_losses(df)['LOSS'].mean()
            if loss < best_loss:
                best_loss = loss
                best_threshold = threshold
        thresholds[label] = best_threshold
        logger.info('Optimum threshold for %s: %g (loss: %g)',
                    label, best_threshold, best_loss)

    df = apply_thresholds(predictions.copy(), thresholds)
    loss = calculate_losses(df)['LOSS'].mean()
    logger.info('Loss with all thresholds applied: %g', loss)

    return thresholds


def apply_thresholds(predictions: pd.DataFrame, thresholds: Dict[str, float]) -> pd.DataFrame:
    for label, threshold in thresholds.items():
        mask = predictions[label] > threshold
        predictions.loc[mask, label] = (1 - 1e-15)
        for other_label in [l.name for l in GAPLabel if l.name != label]:
            predictions.loc[mask, other_label] = 1e-15
    return predictions


def calculate_losses(predictions: pd.DataFrame) -> pd.DataFrame:
    loss_func = nn.NLLLoss(reduction='none')
    yhat = torch.from_numpy(predictions[[l.name for l in GAPLabel]].values)
    y = torch.from_numpy(predictions['LABEL'].map({'A': 0, 'B': 1, 'NEITHER': 2}).values)
    loss = loss_func(torch.log(yhat), y).numpy()
    predictions['LOSS'] = loss
    return predictions


def predict(model_dir: Path, device: torch.device) -> None:
    config = Config.load(model_dir / 'config.json')

    model = Model(config, device).cuda()
    model_path = str(model_dir / 'model.pickle')
    model.load_state_dict(torch.load(model_path))
    model.eval()

    val_examples = load_train_val_examples(config.random_seed)[1]
    logger.info('Generating predictions for %d validation examples', len(val_examples))
    predictions = generate_predictions(model, config, val_examples)

    thresholds = optimize_thresholds(predictions, threshold_steps=1000)
    apply_thresholds(predictions, thresholds)
    calculate_losses(predictions)
    predictions.to_csv(model_dir / 'val_predictions.csv', index=False)

    test_examples = load_test_examples()
    logger.info('Generating predictions for %d test examples', len(test_examples))
    predictions = generate_predictions(model, config, test_examples)
    apply_thresholds(predictions, thresholds)
    predictions.to_csv(model_dir / 'test_predictions.csv', index=False)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', metavar='MODEL_DIR',
        help='Directory with the model output generated by train.py.')
    parser.add_argument('--device', metavar='DEVICE', default='cuda',
        help='PyTorch device to use for computation.')
    args = parser.parse_args()
    model_dir = Path(args.model).resolve()
    device = torch.device(args.device)

    # Logging initialization
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler(model_dir / 'predict.log', mode='w'),
            logging.StreamHandler(),
        ])
    logging.getLogger('pytorch_pretrained_bert').setLevel(logging.WARNING)

    predict(model_dir, device)
